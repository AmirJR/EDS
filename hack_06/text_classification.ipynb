{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    \"\"\" \n",
    "    At the moment we are only splitting the text on space. \n",
    "    To make the classifier more accurate you can add additional steps for processing, like:\n",
    "    make the words lowercase, \n",
    "    reduce the words to their stem, \n",
    "    remove standard stopwords like I, the, a, of etc,\n",
    "    remove HTML tags,\n",
    "    split on other characters like :.(){}\n",
    "    \"\"\"\n",
    "    return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_folder = './IMDB/train/'\n",
    "\n",
    "training_set_entries = []\n",
    "\n",
    "labels = ['pos', 'neg']\n",
    "for label in labels:\n",
    "    folder = input_folder + label + '/'\n",
    "    files = listdir(folder)\n",
    "    for filename in files:\n",
    "        with open(folder + filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            words = process_text(\" \".join(lines))\n",
    "            entry = (words, label)\n",
    "            training_set_entries.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print len(training_set_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_dict(list_of_words):\n",
    "    \"\"\"\n",
    "    The NLTK library only accepts entries which are hashable (like a dictionary). \n",
    "    Therefore, if we want to use this library for text classification, we have to turn this list of words into a dict of words.\n",
    "    It seems very inefficient (and it probably is), \n",
    "    \"\"\"\n",
    "    return dict([(word, True) for word in list_of_words])\n",
    "\n",
    "training_set_formatted = [(list_to_dict(element[0]), element[1]) for element in training_set_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the Classifier, we can see which words have the highest probability of being in a positive or negative review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   Avoid = True              neg : pos    =     57.4 : 1.0\n",
      "                    4/10 = True              neg : pos    =     49.0 : 1.0\n",
      "                     Uwe = True              neg : pos    =     35.0 : 1.0\n",
      "                    Boll = True              neg : pos    =     30.3 : 1.0\n",
      "                    3/10 = True              neg : pos    =     29.8 : 1.0\n",
      "               pathetic. = True              neg : pos    =     29.4 : 1.0\n",
      "             excellently = True              pos : neg    =     28.3 : 1.0\n",
      "                   8/10. = True              pos : neg    =     27.0 : 1.0\n",
      "                  Seagal = True              neg : pos    =     27.0 : 1.0\n",
      "              atrocious. = True              neg : pos    =     25.7 : 1.0\n",
      "                   WORST = True              neg : pos    =     25.4 : 1.0\n",
      "                boredom. = True              neg : pos    =     24.3 : 1.0\n",
      "                  awful. = True              neg : pos    =     23.2 : 1.0\n",
      "               awful.<br = True              neg : pos    =     23.0 : 1.0\n",
      "                   MST3K = True              neg : pos    =     22.4 : 1.0\n",
      "               Excellent = True              pos : neg    =     22.1 : 1.0\n",
      "                  Peters = True              pos : neg    =     21.7 : 1.0\n",
      "               horrible. = True              neg : pos    =     21.2 : 1.0\n",
      "                    8/10 = True              pos : neg    =     20.3 : 1.0\n",
      "                  dumber = True              neg : pos    =     20.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_entries = []\n",
    "input_folder = './IMDB/test/'\n",
    "\n",
    "labels = ['pos', 'neg']\n",
    "for label in labels:\n",
    "    folder = input_folder + label + '/'\n",
    "    files = listdir(folder)\n",
    "    for filename in files:\n",
    "        with open(folder + filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            words = process_text(\" \".join(lines))\n",
    "            entry = (words, label)\n",
    "            test_set_entries.append(entry)\n",
    "\n",
    "test_set_formatted = [(list_to_dict(element[0]), element[1]) for element in test_set_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy on the test set is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83544"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course classify individual texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos neg\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos neg\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n"
     ]
    }
   ],
   "source": [
    "for text, label in test_set_formatted[:20]:\n",
    "    print label, classifier.classify(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can you think of a way to improve the overall accuracy of the NLTK classifier? \n",
    "2. Another classifier which can be used is the Naive Bayes classifier of the scikit-learn package. What is the performance of this classifier under the same conditions.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB() \n",
    "\n",
    "Do you know of any other packages?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
